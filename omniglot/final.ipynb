{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poom's ConvNet for One-Shot Learning on the Omniglob Dataset\n",
    "\n",
    "I follow the approach from [1], which reported a whopping 93.8% accuracy on 20-way one-shot character matching with some slight modifications: \n",
    "\n",
    "* weight decay replaces batch normalization.\n",
    "* rather than downsizing the image, a thin plate spline spatial transformer network is used to crop input images [2]\n",
    "* the elementwise complex norm of the fourier transform of the image is fed through a parallel network of the same architecture whose prediction is combined with the original one using learned weights to obtain the final prediction.\n",
    "* kernels of the first convolutional layer is larger to account for the intuition that larger image means larger features\n",
    "* Munkres assignment algorithm is used to find the maximum probability matching [3]\n",
    "* elastic distortions, small random rotations and small random shearing is used to augment the dataset\n",
    "\n",
    "These weird tricks and some more minor ones allow me to achieve a __prediction acccuracy of 97.8%__ which is almost a third of [1] __using a training set that's 3/4th of the size__. The intuition behind adding the fourier transform is that the elementwise norm of the fourier transform is translation invariant, which is useful when we want features that are independent of the position of the character in the image. (However, rotations commute with fourier transform, so we still need the spatial transformer network.)\n",
    "\n",
    "Disclaimer: the thin-plate spline spatial transfomer network (`crop.py`) is `iwyoo`'s implementation [4].\n",
    "\n",
    "[1] https://arxiv.org/abs/1606.04080  \n",
    "[2] https://arxiv.org/abs/1506.02025  \n",
    "[3] https://en.wikipedia.org/wiki/Hungarian_algorithm  \n",
    "[4] https://github.com/iwyoo/TPS_STN-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eight1911/learn/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import threading\n",
    "\n",
    "import crop\n",
    "import util\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.optimize as opti\n",
    "import numpy.random as rd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threadify(func):\n",
    "    \"function runs in a new thread.\"\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def run(*args, **kwds):\n",
    "        new_thread = threading.Thread(\n",
    "            target = func,\n",
    "            args   = args,\n",
    "            kwargs = kwds)\n",
    "        new_thread.start()\n",
    "        return new_thread\n",
    "\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_cosine(a, b):\n",
    "    \"\"\"\n",
    "    computes the pairwise cosine distance of two batches of vectors\n",
    "    \n",
    "    input\n",
    "    =====\n",
    "    a : a tensor of shape [num_batch, num_features]\n",
    "      - a matrix of features\n",
    "    b : a tensor of shape [num_batch, num_features]\n",
    "      - a matrix of features\n",
    "    \n",
    "    output\n",
    "    ======\n",
    "    m : a square matrix m such that m[i, j] is the\n",
    "        cosine distance between a[i] and b[j]\n",
    "    \"\"\"\n",
    "    a = tf.transpose(a) / tf.norm(a, axis=1)\n",
    "    b = tf.transpose(b) / tf.norm(b, axis=1)\n",
    "    return tf.transpose(a) @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x, pdrop, cropsize):\n",
    "    \"\"\"\n",
    "    the spatial transformer layer of the network, inputs an image\n",
    "    and returns a thin plate spline distorted version of a subimage\n",
    "    of the image that the network thinks will maximize presence of \n",
    "    features\n",
    "    \n",
    "    input\n",
    "    =====\n",
    "    \n",
    "    x : tensor of shape [num_batch, img_width, img_height]\n",
    "      - the image tensor that is raw input of transform network\n",
    "    pdrop : a float tensor or a float\n",
    "      - the dropout probability\n",
    "    cropsize : a tuple (int, int)\n",
    "      - the size of the output image. \n",
    "    \n",
    "    output\n",
    "    ======\n",
    "    img : tensor of shape [num_batch, cropsize[0], cropsize[1], 1]\n",
    "        - the output image\n",
    "    \"\"\"\n",
    "    \n",
    "    # theta is the control points of the thin-plate spline.\n",
    "    theta = tf.reshape(x, [x.shape[0], x.shape[1], x.shape[2], 1])\n",
    "    theta = tf.layers.conv2d(theta, 16, [5, 5], [2, 2], 'same')\n",
    "    theta = tf.layers.max_pooling2d(theta, [2, 2], [2, 2], 'same')\n",
    "    theta = tf.nn.leaky_relu(theta, 0.03)\n",
    "\n",
    "    theta = tf.layers.conv2d(theta, 16, [5, 5], [2, 2], 'same')\n",
    "    theta = tf.layers.max_pooling2d(theta, [2, 2], [2, 2], 'same')\n",
    "    theta = tf.nn.leaky_relu(theta, 0.03)\n",
    "\n",
    "    theta = tf.layers.conv2d(theta, 16, [5, 5], [1, 1], 'same')\n",
    "    theta = tf.nn.leaky_relu(theta, 0.03)\n",
    "\n",
    "    u = theta.shape[1] * theta.shape[2] * theta.shape[3]\n",
    "\n",
    "    theta = tf.reshape(theta, [-1, u])\n",
    "    theta = tf.layers.dropout(theta, pdrop)\n",
    "    theta = tf.layers.dense(theta, 40)\n",
    "    theta = tf.nn.leaky_relu(theta, 0.03)\n",
    "    theta = tf.layers.dropout(theta, pdrop)\n",
    "    theta = tf.layers.dense(theta, 18)\n",
    "\n",
    "    theta = tf.reshape(theta, [-1, 9, 2])\n",
    "    \n",
    "    # Initialze with a preference for zoomed in crops\n",
    "    # this is to force the spatial transformer network\n",
    "    # to \"do or die.\" Either it learns good crops or the \n",
    "    # network performace is compromised.\n",
    "    _x = np.linspace(0.3, -0.3, 3)\n",
    "    _y = np.linspace(0.3, -0.3, 3)\n",
    "    _x, _y = np.meshgrid(_x, _y)\n",
    "    _x = _x.reshape([-1])\n",
    "    _y = _y.reshape([-1])\n",
    "\n",
    "    theta += np.vstack([_x, _y]).T\n",
    "    \n",
    "    return theta, crop.TPS_STN(x, 3, 3, theta, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_norm(image):\n",
    "    \"\"\"\n",
    "    the norm of the fourier transform of the image\n",
    "    \n",
    "    input\n",
    "    =====\n",
    "    x : tensor of shape [num_batch, img_width, img_height]\n",
    "      - the input image\n",
    "    output\n",
    "    ======\n",
    "    u : tensor of shape [num_batch, img_width, img_height / 2]\n",
    "      - the fourier transform of the input image\n",
    "    \"\"\"\n",
    "    image = tf.reshape(image, [image.shape[0], image.shape[1], image.shape[2]])\n",
    "    image = tf.spectral.rfft2d(image)\n",
    "    image = tf.reshape(image, [-1, image.shape[1], image.shape[2], 1])\n",
    "    return tf.sqrt(tf.real(image)**2 + tf.imag(image)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push(x, pdrop):\n",
    "    \"\"\"\n",
    "    the main convolutional layers. we apply this to the image and its \n",
    "    fourier transform in parallel.\n",
    "    \n",
    "    input\n",
    "    =====\n",
    "    x : tensor of shape [num_batch, img_width, img_height]\n",
    "      - the input image\n",
    "    pdrop : a float tensor or a float\n",
    "      - the dropout probability\n",
    "    \n",
    "    output\n",
    "    ======\n",
    "    y : tensor of shape [num_batch, 64]\n",
    "      - the output image (will raise an error if the input image is too big)\n",
    "    \"\"\"\n",
    "    x = tf.layers.conv2d(x, 64, [5, 5], [2, 2], 'same')\n",
    "    x = tf.layers.max_pooling2d(x, [2, 2], [2, 2], 'same')\n",
    "    x = tf.nn.leaky_relu(x, 0.03)\n",
    "\n",
    "    x = tf.layers.conv2d(x, 64, [3, 3], [1, 1], 'same')\n",
    "    x = tf.layers.max_pooling2d(x, [2, 2], [2, 2], 'same')\n",
    "    x = tf.nn.leaky_relu(x, 0.03)\n",
    "\n",
    "    x = tf.layers.conv2d(x, 64, [3, 3], [1, 1], 'same')\n",
    "    x = tf.layers.max_pooling2d(x, [2, 2], [2, 2], 'same')\n",
    "    x = tf.nn.leaky_relu(x, 0.03)\n",
    "\n",
    "    x = tf.layers.conv2d(x, 64, [3, 3], [1, 1], 'same')\n",
    "    x = tf.layers.average_pooling2d(x, [2, 2], [2, 2], 'same')\n",
    "\n",
    "    return tf.reshape(x, [x.shape[0], 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you might notice that save for the spatial transformer layer, each layer in our network $\\mathcal{N}$ has the property that for any scalar $c \\in \\mathbb{R}$\n",
    "   $$ \\mathcal{N}(c\\cdot\\text{image}) = c\\mathcal{N}(\\text{image}). $$\n",
    "\n",
    "which is quite a nice property because I expect that the saturation and the brightness of the image should not affect the output of the network. However, since the norm of the output is independent of its direction, and since I am using the cosine distance which is independent of the norm, the magnitude of the weights in collective do not affect the prediction of the network. Because of this, using weight decay may cause the weights to go so low that the predictions become unstable. To solve this problem, I also added another regularization condition that the norm of the output is approximately 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I define a class that puts everything together (including a function for training the network and one for predicting inputs.) In particular, you may notice that I choose to add the confusion matrix of the prediction of the fourier transform convnet and the regular image convnet rather than concatenate their output vectors and compute the confusion matrix from one final vector. This is (a.) to make it possible so that I can learn their relative contribution (using `self.balancer`) and (b.) to get two relatively independent predictions rather than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchingNetwork:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.inpsize = (105, 105)\n",
    "        self.cropsize = (32, 32)\n",
    "\n",
    "        self.pdrop = tf.placeholder(tf.float32)\n",
    "        self.rate = tf.placeholder(tf.float32)\n",
    "        self.inp = tf.placeholder(tf.float32, [2*k, *self.inpsize])\n",
    "\n",
    "        self.x = tf.reshape(self.inp, [*self.inp.shape, 1])\n",
    "        self.theta, self.t = transform(self.x, self.pdrop, self.cropsize)\n",
    "        self.t = tf.reshape(self.t, [2*k, *self.cropsize, 1])\n",
    "        self.u = tf.minimum(fft_norm(self.t) / 10, 10)\n",
    "\n",
    "        self.y = push(self.t, self.pdrop)\n",
    "        self.z = push(self.u, self.pdrop)\n",
    "\n",
    "        # start with high confidence\n",
    "        self.balancer = (wy, wz, wmax, wmin) = [\n",
    "            tf.Variable(2.0, dtype=tf.float32),\n",
    "            tf.Variable(2.0, dtype=tf.float32),\n",
    "            tf.Variable(2.0, dtype=tf.float32),\n",
    "            tf.Variable(2.0, dtype=tf.float32),\n",
    "        ]\n",
    "\n",
    "        self.yconfusion = pairwise_cosine(self.y[:k], self.y[k:])\n",
    "        self.zconfusion = pairwise_cosine(self.z[:k], self.z[k:])\n",
    "        self.confusion = (wy * self.yconfusion \n",
    "                        + wz * self.zconfusion\n",
    "                        + wmax * tf.maximum(self.yconfusion, self.zconfusion)\n",
    "                        + wmin * tf.minimum(self.yconfusion, self.zconfusion))\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.rate / tf.norm(self.balancer))\n",
    "\n",
    "        # penalize vectors that are too large or too small\n",
    "        self.normloss = (tf.reduce_mean((tf.norm(self.y, axis=1) - 1) ** 2)\n",
    "                       + tf.reduce_mean((tf.norm(self.z, axis=1) - 1) ** 2)\n",
    "                       + tf.reduce_mean((tf.norm(self.s, axis=1) - 1) ** 2))\n",
    "        # self.l2loss = tf.reduce_sum([tf.reduce_mean(i**2) for i in tf.trainable_variables()])\n",
    "        self.loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=self.confusion, labels=np.arange(20))\n",
    "        self.train_ops = self.optimizer.minimize(\n",
    "            tf.reduce_sum(self.loss) + self.normloss)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "    def predict(self, aset, bset):\n",
    "        confusion = self.sess.run(self.confusion, feed_dict={\n",
    "            self.inp   : np.vstack([aset, bset]),\n",
    "            self.pdrop : 0.0\n",
    "        })\n",
    "        \n",
    "        exp = np.exp(confusion)\n",
    "        prob = (exp.T / exp.sum(axis=1)).T\n",
    "        logprob = np.log(prob)\n",
    "\n",
    "        # minimize confusion by finding the optimal \n",
    "        # (maximum probability) matching in the complete \n",
    "        # bipartite graph\n",
    "        return opti.linear_sum_assignment(-logprob)\n",
    "\n",
    "    def train(self, aset, bset, rate=1e-4):\n",
    "        # assume that for all i, aset[i] is the \n",
    "        # same character as bset[i]\n",
    "        \n",
    "        # to make sure that this doesn't introduce\n",
    "        # some bugs, we will permute the inputs when\n",
    "        # we test\n",
    "        p = [self.loss, self.train_ops]\n",
    "        l, _ = self.sess.run(p, feed_dict={\n",
    "            self.inp   : np.vstack([aset, bset]),\n",
    "            self.rate  : rate,\n",
    "            self.pdrop : 0.5\n",
    "        })\n",
    "\n",
    "        return l.mean()\n",
    "\n",
    "    def accuracy(self, stream):\n",
    "        apermutator = np.arange(self.k)\n",
    "        bpermutator = np.arange(self.k)\n",
    "        n_correct = 0\n",
    "        for aset, bset in stream:\n",
    "            rd.shuffle(apermutator)\n",
    "            rd.shuffle(bpermutator)\n",
    "            ashuffled = aset[apermutator]\n",
    "            bshuffled = bset[bpermutator]\n",
    "\n",
    "            apred, bpred = self.predict(ashuffled, bshuffled)\n",
    "            # prediction is that\n",
    "            # \n",
    "            #     aset[apermutator][apred] ~= bset[bpermutator][bpred]\n",
    "            # \n",
    "            # but we have that aset ~= bset, therefore, we must\n",
    "            # have that, if our prediction is correct, then\n",
    "            # \n",
    "            #     apermutator[apred] == bpermutator[bpred]\n",
    "            # \n",
    "            nc = np.sum(apermutator[apred] == bpermutator[bpred])\n",
    "            n_correct += nc\n",
    "        return n_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the nitty gritty part starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "rd.seed(0)\n",
    "\n",
    "m = MatchingNetwork(20) # twenty-way matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is shown the output of the untrained spatial transformer network (STN) (left) against the input image (right). Notice how the images are zoomed in. This is to force the STN to either learn weights or compromise the performance of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129856208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aset, bset = util.sample(20, \"testing\")\n",
    "test = m.sess.run(m.t, feed_dict={\n",
    "    m.inp : np.vstack([aset, bset]),\n",
    "    m.pdrop : 0.5\n",
    "})\n",
    "test = test.reshape([-1, 32, 32])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "a = fig.add_subplot(3,2,1)\n",
    "plt.imshow(test[0])\n",
    "a = fig.add_subplot(3,2,2)\n",
    "plt.imshow(aset[0])\n",
    "\n",
    "a = fig.add_subplot(3,2,3)\n",
    "plt.imshow(test[20])\n",
    "a = fig.add_subplot(3,2,4)\n",
    "plt.imshow(bset[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define the function for training below. I partition our data set into three parts. The first one is the training data comprising of 964 characters. The next 100 characters form my validation set (which admittedly is a part of the evaluation set, so I am cheating at little here.) and finally the last 559 characters is my test set. Each character has twenty sample images.\n",
    "\n",
    "One function you will see below is util.sample which has the following signature\n",
    "\n",
    "    util.sample(k : int, mode : string, outsize : int) -> (numpy array, numpy array)\n",
    "   \n",
    "The function is defined in `util.py` and essentially runs samples two images each from `k` different characters, and apply some random augmentations (if `mode == \"training\"`) and return two arrays `(aset, bset)` such that for each `i`, `aset[i]` is the same character as `bset[i]`, but written by two different people. This sampling distribution (save the data augmentation) is follows the implementation in [1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 : 20 : 0.7633333333333334"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matrix contains invalid numeric entries",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1bdcb4e230d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mnc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mhist_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlast_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-60b661f2a943>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mbshuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbpermutator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mapred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mashuffled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbshuffled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;31m# prediction is that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-60b661f2a943>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, aset, bset)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# (maximum probability) matching in the complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# bipartite graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_sum_assignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/learn/lib/python3.6/site-packages/scipy/optimize/_hungarian.py\u001b[0m in \u001b[0;36mlinear_sum_assignment\u001b[0;34m(cost_matrix)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_matrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matrix contains invalid numeric entries\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcost_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matrix contains invalid numeric entries"
     ]
    }
   ],
   "source": [
    "n = 300\n",
    "hist_acc = []\n",
    "rate_exp = -np.arange(12000) / 15000\n",
    "rate_range = np.exp(rate_exp) * 5e-4\n",
    "num_correct = 10\n",
    "for i, rate in enumerate(rate_range):\n",
    "    if i % 6 == 0:\n",
    "        nc = m.accuracy([util.sample(20, \"validating\")])\n",
    "        hist_acc.append(nc)\n",
    "        last_acc = hist_acc[-1]\n",
    "        running_acc = np.mean(hist_acc[-n:])/20\n",
    "        print(f\"\\r{len(hist_acc)} : {last_acc} : {running_acc}\", end=\"\")\n",
    "    aset, bset = util.sample(20, \"training\")\n",
    "    m.train(aset, bset, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 150\n",
    "plt.plot([1 - np.mean(hist_acc[i:i+n]) / 20 for i in range(0, len(hist_acc)-n)])\n",
    "plt.title(\"validation error\")\n",
    "plt.xlabel(\"number of iterations (x6)\")\n",
    "plt.ylabel(f\"average prediction error over {n} trials\")\n",
    "# plt.yscale(\"log\")\n",
    "print(len(hist_acc), \":\", np.mean(np.array(hist_acc[-n:]) * 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_acc = m.accuracy(util.sample(20, \"testing\") for i in range(5000))\n",
    "# print(final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
